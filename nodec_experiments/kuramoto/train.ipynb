{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuramoto: Curriculum Training\n",
    "Below you may find the corresponding trainning proceedure for Kuramoto.\n",
    "This proceedure has been adapted from a script and is expected to fit and produce a NODEC that can control oscillator graphs.\n",
    "\n",
    "Please make sure that the required data folder is available at the paths used by the script.\n",
    "You may generate the required data by running the python script\n",
    "```nodec_experiments/kuramoto/gen_parameters.py```.\n",
    "\n",
    "As neural network intialization is stochastic, please make sure that appropriate seeds are used or expect some variance to paper results.\n",
    "This can be evident as sometimes training does not yield a stable controller.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when developing\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:59:26.358977Z",
     "start_time": "2025-11-04T08:59:26.346717Z"
    }
   },
   "source": [
    "#将仓库根目录（nnc-master/）添加到 Python 系统路径中。\n",
    "#为什么需要？：脚本位于 nnc-master/nodec_experiments/kuramoto/，而要导入的 nnc/ 模块在根目录下。通过 sys.path.append('../../')，Python 才能找到 nnc.controllers、nnc.helpers 等自定义模块，避免导入错误。\n",
    "import os\n",
    "os.sys.path.append('../../')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T08:59:31.924712Z",
     "start_time": "2025-11-04T08:59:28.565077Z"
    }
   },
   "source": [
    "#基础工具库导入\n",
    "import math\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "#可视化工具库导入\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "#Kuramoto 控制相关的模块导入\n",
    "from nnc.controllers.neural_network.nnc_controllers import NNCDynamics\n",
    "from nnc.controllers.baselines.oscillators.dynamics import AdditiveControlKuramotoDynamics\n",
    "from nnc.controllers.baselines.oscillators.optimal_controllers import KuramotoFeedbackControl\n",
    "\n",
    "from nnc.helpers.torch_utils.graphs import adjacency_tensor, maximum_matching_drivers, drivers_to_tensor\n",
    "from nnc.helpers.torch_utils.oscillators import order_parameter_cos\n",
    "#优化版 ODE 求解器，优化计算速度，避免重复计算邻接矩阵相关的操作，尤其适合大规模振子系统\n",
    "from nnc.helpers.torch_utils.numerics import faster_adj_odeint\n",
    "from nnc.helpers.plot_helper import ColorRegistry, base_layout\n",
    "\n",
    "\n",
    "from tqdm.cli import tqdm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\.conda\\envs\\ANNF\\lib\\site-packages\\pandas\\_testing.py:24: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  import pandas._libs.testing as _testing\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchdiffeq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m odeint\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnetworkx\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnx\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#可视化工具库导入\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ANNF\\lib\\site-packages\\pandas\\__init__.py:180\u001B[0m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjson\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _json_normalize \u001B[38;5;28;01mas\u001B[39;00m json_normalize\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tester\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m test\n\u001B[1;32m--> 180\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marrays\u001B[39;00m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# use the closest tagged version if possible\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ANNF\\lib\\site-packages\\pandas\\testing.py:5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mPublic testing utility functions.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      6\u001B[0m     assert_extension_array_equal,\n\u001B[0;32m      7\u001B[0m     assert_frame_equal,\n\u001B[0;32m      8\u001B[0m     assert_index_equal,\n\u001B[0;32m      9\u001B[0m     assert_series_equal,\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_extension_array_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_frame_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_series_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_index_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m ]\n",
      "File \u001B[1;32m~\\.conda\\envs\\ANNF\\lib\\site-packages\\pandas\\_testing.py:24\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrandom\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m rand, randn\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlocalization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     can_set_locale,\n\u001B[0;32m     20\u001B[0m     get_locales,\n\u001B[0;32m     21\u001B[0m     set_locale,\n\u001B[0;32m     22\u001B[0m )\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_testing\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_typing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FilePathOrBuffer, FrameOrSeries\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _get_lzma_file, _import_lzma\n",
      "File \u001B[1;32mpandas\\_libs\\testing.pyx:10\u001B[0m, in \u001B[0;36minit pandas._libs.testing\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ANNF\\lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Params\n",
    "\n",
    "# Torch params\n",
    "device = 'cuda:0'\n",
    "dtype = torch.float \n",
    "\n",
    "# NODEC Params\n",
    "train = True         # retrain or load pretrained model\n",
    "\n",
    "\n",
    "# Feedback Control Params\n",
    "\n",
    "\n",
    "# Paths\n",
    "data_folder = '../../../data/parameters/kuramoto/'\n",
    "result_folder = '../../../results/kuramoto/'\n",
    "os.makedirs(result_folder, exist_ok = True)\n",
    "\n",
    "graph = 'complete'\n",
    "graph_folder = data_folder + graph + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading graph and dynamics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Parameters for the graph\n",
    "\n",
    "\n",
    "A = torch.load(graph_folder + 'adjacency.pt', map_location=device).float() # adjacency matrix\n",
    "G = nx.from_numpy_matrix(A.numpy())\n",
    "n_nodes = G.number_of_nodes()\n",
    "mean_degree = np.mean(list(dict(G.degree()).values()))\n",
    "\n",
    "A = A.to(device, dtype) # adjacency\n",
    "L = A.sum(-1).diag() - A # laplacian\n",
    "\n",
    "# to save results\n",
    "os.makedirs(graph_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dynamics dependendent variables and states\n",
    "coupling_constants = torch.load(data_folder + 'coupling_constants.pt', map_location=device).to(device, dtype)\n",
    "frustration_constants = torch.load(data_folder + 'frustration_constants.pt', map_location=device).to(device, dtype)\n",
    "natural_frequencies = torch.load(data_folder + 'nominal_angular_velocities.pt', map_location=device).to(device, dtype)\n",
    "K = coupling_constants[2].item() # coupling constant, index 2 should be 0.4\n",
    "frustration_constant = frustration_constants[0] # we use no frustration for this example\n",
    "dynamics_params_folder = graph_folder + 'dynamics_parameters/coupling_' + '{:.1f}'.format(K) + '/'\n",
    "\n",
    "\n",
    "x0 = torch.load(data_folder + 'single_init.pt',  map_location=device)\n",
    "\n",
    "\n",
    "# to avoid using extra memory we load the driver vector \n",
    "# and use element-wise multiplication instead of the driver matrix.\n",
    "gain_vector = torch.load(dynamics_params_folder + 'driver_vector.pt', map_location=device).to(device, dtype)\n",
    "driver_nodes = torch.nonzero(gain_vector).cpu().numpy().flatten().tolist()\n",
    "driver_percentage = len(driver_nodes)/len(gain_vector)\n",
    "steady_state = torch.load(dynamics_params_folder + 'steady_state.pt', map_location=device).to(device, dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Feedback Control Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Controller parameters\n",
    "# Feedback Control\n",
    "feedback_control_constant = 10\n",
    "\n",
    "# Neural Network training\n",
    "n_hidden_units = 3\n",
    "batch_size = 8 # for code ocean GPUs this might be too much, \n",
    "               # reduce to 4 or 2 but stability of learned control may suffer.\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current experiment info:')\n",
    "print('\\t Loaded ' + graph + 'graph with: ' + str(n_nodes) + ' nodes and ' + str(G.number_of_edges()) + ' edges.' )\n",
    "print('\\t Coupling Constant: ' + str(K))\n",
    "print('\\t Frustration Constant: ' + str(frustration_constant.item()))\n",
    "print('\\t Natural Frequencies: mean: ' + str(natural_frequencies.mean().item()) + ' variance: ' + str(natural_frequencies.var().item()) )\n",
    "print('\\t Ratio of driver node vs total nodes: '  + str(len(driver_nodes)/n_nodes))\n",
    "print('\\t Feedback Control Constant: '  + str(feedback_control_constant))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the dynamics:\n",
    "dyn = AdditiveControlKuramotoDynamics(\n",
    "    A, \n",
    "    K, \n",
    "    natural_frequencies,\n",
    "    frustration_constant=frustration_constant\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a trajectory without control\n",
    "tlin = torch.linspace(0, 150, 500).to(device)\n",
    "state_trajectory_noc = odeint(lambda t,y: dyn(t,y,u=None),x0, tlin, method='dopri5')\n",
    "y=order_parameter_cos(state_trajectory_noc.squeeze().cpu())\n",
    "fig_noc = px.line(y=y.cpu().numpy(), x=tlin.cpu().numpy())\n",
    "fig_noc.data[0].name = 'No control'\n",
    "fig_noc.data[0].line.color = ColorRegistry.constant\n",
    "fig_noc.data[0].showlegend = True\n",
    "fig_noc.layout.xaxis.title.text = 'Time'\n",
    "fig_noc.layout.yaxis.title.text = '$r(t)$'\n",
    "fig_noc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results with feedback control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating feecback control trajectory\n",
    "cont = lambda x: feedback_control_constant*gain_vector*torch.sin(-x)\n",
    "state_trajectory_oc = odeint(lambda t,y: dyn(t,y.detach(),u=cont(y).detach()), \n",
    "            x0,\n",
    "            torch.linspace(0, 150, 500).to(device), \n",
    "            method='dopri5'\n",
    "           )\n",
    "y=order_parameter_cos(state_trajectory_oc.squeeze().cpu())\n",
    "fig_fc = px.line(y=y.cpu().numpy(), x=torch.linspace(0, 150, 500).numpy())\n",
    "fig_fc = px.line(y=y.cpu().numpy(), x=tlin.cpu().numpy())\n",
    "fig_fc.data[0].name = 'Feedback Control'\n",
    "fig_fc.data[0].line.color = ColorRegistry.oc\n",
    "fig_fc.data[0].showlegend = True\n",
    "fig_fc.layout.xaxis.title.text = 'Time'\n",
    "fig_fc.layout.yaxis.title.text = '$r(t)$'\n",
    "fig_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NODEC\n",
    "Since we developed Kuramoto recently, we choose to provide the curriculum learning and the architecture in the notebook.\n",
    "After unit testing we will include it in the main library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback control neural network\n",
    "class EluFeedbackControl(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Very simple Elu architecture for control of linear systems\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes, n_drivers, driver_matrix, n_hidden=3):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(n_nodes,n_hidden)\n",
    "        self.linear_h1 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear_final = torch.nn.Linear(n_hidden, n_drivers)\n",
    "        self.driver_matrix = driver_matrix\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        :param t: A scalar or a batch with scalars\n",
    "        :param x: input_states for all nodes\n",
    "        :return:\n",
    "        \"\"\"     \n",
    "        u = self.linear(torch.sin(x))\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_h1(u)\n",
    "        u = torch.nn.functional.elu(u)\n",
    "        u = self.linear_final(u)\n",
    "        # we multiply by the nn driver matrix to generate the control signal\n",
    "        u = (self.driver_matrix@u.unsqueeze(-1)).squeeze(-1)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the driver vector back to a matrix \n",
    "# and convert the non-zero elements to 1, so that the neural network is agnostic of the exact gain values.\n",
    "driver_matrix = drivers_to_tensor(A.shape[-1], driver_nodes).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set a seed for NN weight generation to try to make results as reproducible as possible:\n",
    "torch.manual_seed(3548)\n",
    "neural_net = EluFeedbackControl(n_nodes,\n",
    "                                len(driver_nodes), \n",
    "                                driver_matrix,\n",
    "                                n_hidden=n_hidden_units\n",
    "                               ).to(dtype=dtype, device=device)\n",
    "\n",
    "for param, dat in neural_net.named_parameters():\n",
    "    if 'bias' not in param:\n",
    "        torch.nn.init.xavier_normal_(dat)\n",
    "        # we initialize close to 0 to avoid learning high energy solutions\n",
    "        dat = dat/1000\n",
    "nnc_dyn = NNCDynamics(dyn, neural_net).to(dtype=dtype, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neural_net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training with curriculum\n",
    "Please notice how the batch trainning and curriculum learning proceedures operate on lines 8 and 24 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    pbar = tqdm(range(epochs))\n",
    "    trajectory_length = [1]\n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "        def closure():\n",
    "            # sample new minibatch for training\n",
    "            sample = torch.randn([batch_size, 1, n_nodes]).to(device)\n",
    "            state_samples = 100\n",
    "            x_reached = faster_adj_odeint(nnc_dyn, \n",
    "                                          sample,\n",
    "                                          torch.linspace(0,\n",
    "                                                         trajectory_length[0],\n",
    "                                                         state_samples).to(device), \n",
    "                                       method='dopri5', \n",
    "                               #adjoint_params=neural_net.parameters()\n",
    "                              )[1:]        \n",
    "\n",
    "            op = order_parameter_cos(x_reached)\n",
    "            loss =  (-op.mean(-1) - op.min(-1).values).mean()       \n",
    "            loss.backward()\n",
    "            loss_value = loss.item()\n",
    "            pbar.set_postfix({'Training loss: ' :  str(round(loss_value,2)) ,  \n",
    "                              'trajectory length in time units: ' : str(round(trajectory_length[0], 2))})\n",
    "            # increase trajectory by sampling a uniform distribution in [0,2]\n",
    "            trajectory_length[0] = trajectory_length[0]+2*torch.rand(1).item()\n",
    "            return loss.item()\n",
    "        \n",
    "\n",
    "        try:\n",
    "            optimizer.step(closure)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    torch.save(neural_net.state_dict(), result_folder + 'trained_model.pt')\n",
    "else: \n",
    "    neural_net.load_state_dict(torch.load( '../../../data/parameters/kuramoto/erdos_renyi/trained_model.pt',  \n",
    "                                          map_location=device)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neural_net.state_dict(), result_folder + 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "tlin = torch.linspace(0, 150, 500).to(device)\n",
    "state_trajectory_nn = odeint( lambda t,y: dyn(t,y.detach(),u=nnc_dyn.nnc.neural_net(t, y.detach())), \n",
    "            x0,\n",
    "            tlin, method='dopri5',\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NODEC Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = order_parameter_cos(state_trajectory_nn.cpu().detach())\n",
    "\n",
    "px.line(y=y.cpu().numpy().flatten(), x = tlin.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
